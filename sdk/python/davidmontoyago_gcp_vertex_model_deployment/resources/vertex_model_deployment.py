# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from . import outputs
from ._inputs import *

__all__ = ['VertexModelDeploymentArgs', 'VertexModelDeployment']

@pulumi.input_type
class VertexModelDeploymentArgs:
    def __init__(__self__, *,
                 model_image_url: pulumi.Input[_builtins.str],
                 project_id: pulumi.Input[_builtins.str],
                 region: pulumi.Input[_builtins.str],
                 service_account: pulumi.Input[_builtins.str],
                 args: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 endpoint_model_deployment: Optional[pulumi.Input['EndpointModelDeploymentArgsArgs']] = None,
                 env: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 health_route: Optional[pulumi.Input[_builtins.str]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 model_artifacts_bucket_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 model_prediction_behavior_schema_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 model_prediction_input_schema_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 model_prediction_output_schema_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 port: Optional[pulumi.Input[_builtins.int]] = None,
                 predict_route: Optional[pulumi.Input[_builtins.str]] = None):
        """
        The set of arguments for constructing a VertexModelDeployment resource.
        :param pulumi.Input[_builtins.str] model_image_url: Vertex AI Image URL of a custom or prebuilt container model server. See: https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers
        :param pulumi.Input[_builtins.str] project_id: Google Cloud Project ID
        :param pulumi.Input[_builtins.str] region: Google Cloud region
        :param pulumi.Input[_builtins.str] service_account: Service account for the model. If ModelImage is pointing to a private registry, this service account must have read access to the registry.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] args: Dockerized model server command line arguments
        :param pulumi.Input['EndpointModelDeploymentArgsArgs'] endpoint_model_deployment: Configuration for deploying the model to a Vertex AI endpoint. Leave empty to upload model only for batched predictions.
        :param pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]] env: Environment variables
        :param pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]] labels: Labels for the deployment
        :param pulumi.Input[_builtins.str] model_artifacts_bucket_uri: Bucket URI to the model artifacts. For instance, gs://my-bucket/my-model-artifacts/ - See: https://cloud.google.com/vertex-ai/docs/training/exporting-model-artifacts
        :param pulumi.Input[_builtins.str] model_prediction_behavior_schema_uri: Bucket URI to the schema for the model inference behavior
        :param pulumi.Input[_builtins.str] model_prediction_input_schema_uri: Bucket URI to the schema for the model input
        :param pulumi.Input[_builtins.str] model_prediction_output_schema_uri: Bucket URI to the schema for the model output
        :param pulumi.Input[_builtins.int] port: Port for the model server. Defaults to 8080.
        """
        pulumi.set(__self__, "model_image_url", model_image_url)
        pulumi.set(__self__, "project_id", project_id)
        pulumi.set(__self__, "region", region)
        pulumi.set(__self__, "service_account", service_account)
        if args is not None:
            pulumi.set(__self__, "args", args)
        if endpoint_model_deployment is not None:
            pulumi.set(__self__, "endpoint_model_deployment", endpoint_model_deployment)
        if env is not None:
            pulumi.set(__self__, "env", env)
        if health_route is not None:
            pulumi.set(__self__, "health_route", health_route)
        if labels is not None:
            pulumi.set(__self__, "labels", labels)
        if model_artifacts_bucket_uri is not None:
            pulumi.set(__self__, "model_artifacts_bucket_uri", model_artifacts_bucket_uri)
        if model_prediction_behavior_schema_uri is not None:
            pulumi.set(__self__, "model_prediction_behavior_schema_uri", model_prediction_behavior_schema_uri)
        if model_prediction_input_schema_uri is not None:
            pulumi.set(__self__, "model_prediction_input_schema_uri", model_prediction_input_schema_uri)
        if model_prediction_output_schema_uri is not None:
            pulumi.set(__self__, "model_prediction_output_schema_uri", model_prediction_output_schema_uri)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if predict_route is not None:
            pulumi.set(__self__, "predict_route", predict_route)

    @_builtins.property
    @pulumi.getter(name="modelImageUrl")
    def model_image_url(self) -> pulumi.Input[_builtins.str]:
        """
        Vertex AI Image URL of a custom or prebuilt container model server. See: https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers
        """
        return pulumi.get(self, "model_image_url")

    @model_image_url.setter
    def model_image_url(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "model_image_url", value)

    @_builtins.property
    @pulumi.getter(name="projectId")
    def project_id(self) -> pulumi.Input[_builtins.str]:
        """
        Google Cloud Project ID
        """
        return pulumi.get(self, "project_id")

    @project_id.setter
    def project_id(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "project_id", value)

    @_builtins.property
    @pulumi.getter
    def region(self) -> pulumi.Input[_builtins.str]:
        """
        Google Cloud region
        """
        return pulumi.get(self, "region")

    @region.setter
    def region(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "region", value)

    @_builtins.property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> pulumi.Input[_builtins.str]:
        """
        Service account for the model. If ModelImage is pointing to a private registry, this service account must have read access to the registry.
        """
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "service_account", value)

    @_builtins.property
    @pulumi.getter
    def args(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]:
        """
        Dockerized model server command line arguments
        """
        return pulumi.get(self, "args")

    @args.setter
    def args(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "args", value)

    @_builtins.property
    @pulumi.getter(name="endpointModelDeployment")
    def endpoint_model_deployment(self) -> Optional[pulumi.Input['EndpointModelDeploymentArgsArgs']]:
        """
        Configuration for deploying the model to a Vertex AI endpoint. Leave empty to upload model only for batched predictions.
        """
        return pulumi.get(self, "endpoint_model_deployment")

    @endpoint_model_deployment.setter
    def endpoint_model_deployment(self, value: Optional[pulumi.Input['EndpointModelDeploymentArgsArgs']]):
        pulumi.set(self, "endpoint_model_deployment", value)

    @_builtins.property
    @pulumi.getter
    def env(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]:
        """
        Environment variables
        """
        return pulumi.get(self, "env")

    @env.setter
    def env(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "env", value)

    @_builtins.property
    @pulumi.getter(name="healthRoute")
    def health_route(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "health_route")

    @health_route.setter
    def health_route(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "health_route", value)

    @_builtins.property
    @pulumi.getter
    def labels(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]:
        """
        Labels for the deployment
        """
        return pulumi.get(self, "labels")

    @labels.setter
    def labels(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]]):
        pulumi.set(self, "labels", value)

    @_builtins.property
    @pulumi.getter(name="modelArtifactsBucketUri")
    def model_artifacts_bucket_uri(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Bucket URI to the model artifacts. For instance, gs://my-bucket/my-model-artifacts/ - See: https://cloud.google.com/vertex-ai/docs/training/exporting-model-artifacts
        """
        return pulumi.get(self, "model_artifacts_bucket_uri")

    @model_artifacts_bucket_uri.setter
    def model_artifacts_bucket_uri(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "model_artifacts_bucket_uri", value)

    @_builtins.property
    @pulumi.getter(name="modelPredictionBehaviorSchemaUri")
    def model_prediction_behavior_schema_uri(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Bucket URI to the schema for the model inference behavior
        """
        return pulumi.get(self, "model_prediction_behavior_schema_uri")

    @model_prediction_behavior_schema_uri.setter
    def model_prediction_behavior_schema_uri(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "model_prediction_behavior_schema_uri", value)

    @_builtins.property
    @pulumi.getter(name="modelPredictionInputSchemaUri")
    def model_prediction_input_schema_uri(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Bucket URI to the schema for the model input
        """
        return pulumi.get(self, "model_prediction_input_schema_uri")

    @model_prediction_input_schema_uri.setter
    def model_prediction_input_schema_uri(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "model_prediction_input_schema_uri", value)

    @_builtins.property
    @pulumi.getter(name="modelPredictionOutputSchemaUri")
    def model_prediction_output_schema_uri(self) -> Optional[pulumi.Input[_builtins.str]]:
        """
        Bucket URI to the schema for the model output
        """
        return pulumi.get(self, "model_prediction_output_schema_uri")

    @model_prediction_output_schema_uri.setter
    def model_prediction_output_schema_uri(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "model_prediction_output_schema_uri", value)

    @_builtins.property
    @pulumi.getter
    def port(self) -> Optional[pulumi.Input[_builtins.int]]:
        """
        Port for the model server. Defaults to 8080.
        """
        return pulumi.get(self, "port")

    @port.setter
    def port(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "port", value)

    @_builtins.property
    @pulumi.getter(name="predictRoute")
    def predict_route(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "predict_route")

    @predict_route.setter
    def predict_route(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "predict_route", value)


@pulumi.type_token("gcp-vertex-model-deployment:resources:VertexModelDeployment")
class VertexModelDeployment(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 args: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 endpoint_model_deployment: Optional[pulumi.Input[Union['EndpointModelDeploymentArgsArgs', 'EndpointModelDeploymentArgsArgsDict']]] = None,
                 env: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 health_route: Optional[pulumi.Input[_builtins.str]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 model_artifacts_bucket_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 model_image_url: Optional[pulumi.Input[_builtins.str]] = None,
                 model_prediction_behavior_schema_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 model_prediction_input_schema_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 model_prediction_output_schema_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 port: Optional[pulumi.Input[_builtins.int]] = None,
                 predict_route: Optional[pulumi.Input[_builtins.str]] = None,
                 project_id: Optional[pulumi.Input[_builtins.str]] = None,
                 region: Optional[pulumi.Input[_builtins.str]] = None,
                 service_account: Optional[pulumi.Input[_builtins.str]] = None,
                 __props__=None):
        """
        Deploys a model to a Vertex AI endpoint

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[Sequence[pulumi.Input[_builtins.str]]] args: Dockerized model server command line arguments
        :param pulumi.Input[Union['EndpointModelDeploymentArgsArgs', 'EndpointModelDeploymentArgsArgsDict']] endpoint_model_deployment: Configuration for deploying the model to a Vertex AI endpoint. Leave empty to upload model only for batched predictions.
        :param pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]] env: Environment variables
        :param pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]] labels: Labels for the deployment
        :param pulumi.Input[_builtins.str] model_artifacts_bucket_uri: Bucket URI to the model artifacts. For instance, gs://my-bucket/my-model-artifacts/ - See: https://cloud.google.com/vertex-ai/docs/training/exporting-model-artifacts
        :param pulumi.Input[_builtins.str] model_image_url: Vertex AI Image URL of a custom or prebuilt container model server. See: https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers
        :param pulumi.Input[_builtins.str] model_prediction_behavior_schema_uri: Bucket URI to the schema for the model inference behavior
        :param pulumi.Input[_builtins.str] model_prediction_input_schema_uri: Bucket URI to the schema for the model input
        :param pulumi.Input[_builtins.str] model_prediction_output_schema_uri: Bucket URI to the schema for the model output
        :param pulumi.Input[_builtins.int] port: Port for the model server. Defaults to 8080.
        :param pulumi.Input[_builtins.str] project_id: Google Cloud Project ID
        :param pulumi.Input[_builtins.str] region: Google Cloud region
        :param pulumi.Input[_builtins.str] service_account: Service account for the model. If ModelImage is pointing to a private registry, this service account must have read access to the registry.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: VertexModelDeploymentArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        Deploys a model to a Vertex AI endpoint

        :param str resource_name: The name of the resource.
        :param VertexModelDeploymentArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(VertexModelDeploymentArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 args: Optional[pulumi.Input[Sequence[pulumi.Input[_builtins.str]]]] = None,
                 endpoint_model_deployment: Optional[pulumi.Input[Union['EndpointModelDeploymentArgsArgs', 'EndpointModelDeploymentArgsArgsDict']]] = None,
                 env: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 health_route: Optional[pulumi.Input[_builtins.str]] = None,
                 labels: Optional[pulumi.Input[Mapping[str, pulumi.Input[_builtins.str]]]] = None,
                 model_artifacts_bucket_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 model_image_url: Optional[pulumi.Input[_builtins.str]] = None,
                 model_prediction_behavior_schema_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 model_prediction_input_schema_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 model_prediction_output_schema_uri: Optional[pulumi.Input[_builtins.str]] = None,
                 port: Optional[pulumi.Input[_builtins.int]] = None,
                 predict_route: Optional[pulumi.Input[_builtins.str]] = None,
                 project_id: Optional[pulumi.Input[_builtins.str]] = None,
                 region: Optional[pulumi.Input[_builtins.str]] = None,
                 service_account: Optional[pulumi.Input[_builtins.str]] = None,
                 __props__=None):
        opts = pulumi.ResourceOptions.merge(_utilities.get_resource_opts_defaults(), opts)
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = VertexModelDeploymentArgs.__new__(VertexModelDeploymentArgs)

            __props__.__dict__["args"] = args
            __props__.__dict__["endpoint_model_deployment"] = endpoint_model_deployment
            __props__.__dict__["env"] = env
            __props__.__dict__["health_route"] = health_route
            __props__.__dict__["labels"] = labels
            __props__.__dict__["model_artifacts_bucket_uri"] = model_artifacts_bucket_uri
            if model_image_url is None and not opts.urn:
                raise TypeError("Missing required property 'model_image_url'")
            __props__.__dict__["model_image_url"] = model_image_url
            __props__.__dict__["model_prediction_behavior_schema_uri"] = model_prediction_behavior_schema_uri
            __props__.__dict__["model_prediction_input_schema_uri"] = model_prediction_input_schema_uri
            __props__.__dict__["model_prediction_output_schema_uri"] = model_prediction_output_schema_uri
            __props__.__dict__["port"] = port
            __props__.__dict__["predict_route"] = predict_route
            if project_id is None and not opts.urn:
                raise TypeError("Missing required property 'project_id'")
            __props__.__dict__["project_id"] = project_id
            if region is None and not opts.urn:
                raise TypeError("Missing required property 'region'")
            __props__.__dict__["region"] = region
            if service_account is None and not opts.urn:
                raise TypeError("Missing required property 'service_account'")
            __props__.__dict__["service_account"] = service_account
            __props__.__dict__["create_time"] = None
            __props__.__dict__["deployed_model_id"] = None
            __props__.__dict__["endpoint_name"] = None
            __props__.__dict__["model_name"] = None
        super(VertexModelDeployment, __self__).__init__(
            'gcp-vertex-model-deployment:resources:VertexModelDeployment',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None) -> 'VertexModelDeployment':
        """
        Get an existing VertexModelDeployment resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = VertexModelDeploymentArgs.__new__(VertexModelDeploymentArgs)

        __props__.__dict__["args"] = None
        __props__.__dict__["create_time"] = None
        __props__.__dict__["deployed_model_id"] = None
        __props__.__dict__["endpoint_model_deployment"] = None
        __props__.__dict__["endpoint_name"] = None
        __props__.__dict__["env"] = None
        __props__.__dict__["health_route"] = None
        __props__.__dict__["labels"] = None
        __props__.__dict__["model_artifacts_bucket_uri"] = None
        __props__.__dict__["model_image_url"] = None
        __props__.__dict__["model_name"] = None
        __props__.__dict__["model_prediction_behavior_schema_uri"] = None
        __props__.__dict__["model_prediction_input_schema_uri"] = None
        __props__.__dict__["model_prediction_output_schema_uri"] = None
        __props__.__dict__["port"] = None
        __props__.__dict__["predict_route"] = None
        __props__.__dict__["project_id"] = None
        __props__.__dict__["region"] = None
        __props__.__dict__["service_account"] = None
        return VertexModelDeployment(resource_name, opts=opts, __props__=__props__)

    @_builtins.property
    @pulumi.getter
    def args(self) -> pulumi.Output[Optional[Sequence[_builtins.str]]]:
        """
        Dockerized model server command line arguments
        """
        return pulumi.get(self, "args")

    @_builtins.property
    @pulumi.getter(name="createTime")
    def create_time(self) -> pulumi.Output[_builtins.str]:
        """
        Creation timestamp
        """
        return pulumi.get(self, "create_time")

    @_builtins.property
    @pulumi.getter(name="deployedModelId")
    def deployed_model_id(self) -> pulumi.Output[_builtins.str]:
        """
        ID of the deployed model
        """
        return pulumi.get(self, "deployed_model_id")

    @_builtins.property
    @pulumi.getter(name="endpointModelDeployment")
    def endpoint_model_deployment(self) -> pulumi.Output[Optional['outputs.EndpointModelDeploymentArgs']]:
        """
        Configuration for deploying the model to a Vertex AI endpoint. Leave empty to upload model only for batched predictions.
        """
        return pulumi.get(self, "endpoint_model_deployment")

    @_builtins.property
    @pulumi.getter(name="endpointName")
    def endpoint_name(self) -> pulumi.Output[_builtins.str]:
        """
        Full name of the endpoint
        """
        return pulumi.get(self, "endpoint_name")

    @_builtins.property
    @pulumi.getter
    def env(self) -> pulumi.Output[Optional[Mapping[str, _builtins.str]]]:
        """
        Environment variables
        """
        return pulumi.get(self, "env")

    @_builtins.property
    @pulumi.getter(name="healthRoute")
    def health_route(self) -> pulumi.Output[Optional[_builtins.str]]:
        return pulumi.get(self, "health_route")

    @_builtins.property
    @pulumi.getter
    def labels(self) -> pulumi.Output[Optional[Mapping[str, _builtins.str]]]:
        """
        Labels for the deployment
        """
        return pulumi.get(self, "labels")

    @_builtins.property
    @pulumi.getter(name="modelArtifactsBucketUri")
    def model_artifacts_bucket_uri(self) -> pulumi.Output[Optional[_builtins.str]]:
        """
        Bucket URI to the model artifacts. For instance, gs://my-bucket/my-model-artifacts/ - See: https://cloud.google.com/vertex-ai/docs/training/exporting-model-artifacts
        """
        return pulumi.get(self, "model_artifacts_bucket_uri")

    @_builtins.property
    @pulumi.getter(name="modelImageUrl")
    def model_image_url(self) -> pulumi.Output[_builtins.str]:
        """
        Vertex AI Image URL of a custom or prebuilt container model server. See: https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers
        """
        return pulumi.get(self, "model_image_url")

    @_builtins.property
    @pulumi.getter(name="modelName")
    def model_name(self) -> pulumi.Output[_builtins.str]:
        return pulumi.get(self, "model_name")

    @_builtins.property
    @pulumi.getter(name="modelPredictionBehaviorSchemaUri")
    def model_prediction_behavior_schema_uri(self) -> pulumi.Output[Optional[_builtins.str]]:
        """
        Bucket URI to the schema for the model inference behavior
        """
        return pulumi.get(self, "model_prediction_behavior_schema_uri")

    @_builtins.property
    @pulumi.getter(name="modelPredictionInputSchemaUri")
    def model_prediction_input_schema_uri(self) -> pulumi.Output[Optional[_builtins.str]]:
        """
        Bucket URI to the schema for the model input
        """
        return pulumi.get(self, "model_prediction_input_schema_uri")

    @_builtins.property
    @pulumi.getter(name="modelPredictionOutputSchemaUri")
    def model_prediction_output_schema_uri(self) -> pulumi.Output[Optional[_builtins.str]]:
        """
        Bucket URI to the schema for the model output
        """
        return pulumi.get(self, "model_prediction_output_schema_uri")

    @_builtins.property
    @pulumi.getter
    def port(self) -> pulumi.Output[Optional[_builtins.int]]:
        """
        Port for the model server. Defaults to 8080.
        """
        return pulumi.get(self, "port")

    @_builtins.property
    @pulumi.getter(name="predictRoute")
    def predict_route(self) -> pulumi.Output[Optional[_builtins.str]]:
        return pulumi.get(self, "predict_route")

    @_builtins.property
    @pulumi.getter(name="projectId")
    def project_id(self) -> pulumi.Output[_builtins.str]:
        """
        Google Cloud Project ID
        """
        return pulumi.get(self, "project_id")

    @_builtins.property
    @pulumi.getter
    def region(self) -> pulumi.Output[_builtins.str]:
        """
        Google Cloud region
        """
        return pulumi.get(self, "region")

    @_builtins.property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> pulumi.Output[_builtins.str]:
        """
        Service account for the model. If ModelImage is pointing to a private registry, this service account must have read access to the registry.
        """
        return pulumi.get(self, "service_account")

